#!/bin/bash
# KalamDB Local Cluster Management Script (No Docker)
#
# This script runs a 3-node KalamDB cluster locally without Docker.
# Each node runs as a separate process with its own data directory.
#
# Usage:
#   ./scripts/cluster-local.sh start    - Start the 3-node cluster
#   ./scripts/cluster-local.sh stop     - Stop all nodes
#   ./scripts/cluster-local.sh restart  - Restart the cluster
#   ./scripts/cluster-local.sh status   - Check cluster status
#   ./scripts/cluster-local.sh logs N   - View logs from node N (1, 2, or 3)
#   ./scripts/cluster-local.sh clean    - Stop and remove all data
#   ./scripts/cluster-local.sh build    - Build the server binary
#
# Prerequisites:
#   - Rust toolchain installed (cargo, rustc)
#   - Port 8081, 8082, 8083 available (HTTP)
#   - Port 9081, 9082, 9083 available (Raft RPC)

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
CLUSTER_DATA_DIR="$PROJECT_ROOT/.cluster-local"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Node configuration
NODE1_HTTP=8081
NODE1_RPC=9081
NODE1_ID=1

NODE2_HTTP=8082
NODE2_RPC=9082
NODE2_ID=2

NODE3_HTTP=8083
NODE3_RPC=9083
NODE3_ID=3

print_header() {
    echo ""
    echo -e "${BLUE}╔═══════════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${BLUE}║        KalamDB Local Cluster (No Docker)                          ║${NC}"
    echo -e "${BLUE}╚═══════════════════════════════════════════════════════════════════╝${NC}"
    echo ""
}

check_rust() {
    if ! command -v cargo &> /dev/null; then
        echo -e "${RED}Error: Cargo is not installed${NC}"
        echo "Please install Rust: https://rustup.rs/"
        exit 1
    fi
}

build_server() {
    print_header
    echo -e "${YELLOW}Building KalamDB server...${NC}"
    cd "$PROJECT_ROOT/backend"
    cargo build --release
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}✓ Server built successfully${NC}"
    else
        echo -e "${RED}✗ Build failed${NC}"
        exit 1
    fi
}

create_node_config() {
    local node_id=$1
    local http_port=$2
    local rpc_port=$3
    local data_dir="$CLUSTER_DATA_DIR/node$node_id"
    local config_file="$data_dir/server.toml"

    mkdir -p "$data_dir"
    mkdir -p "$data_dir/data"
    mkdir -p "$data_dir/logs"

    # Get peer addresses (all nodes except self)
    local peers=""
    if [ "$node_id" != "1" ]; then
        peers="${peers}\"127.0.0.1:$NODE1_RPC\","
    fi
    if [ "$node_id" != "2" ]; then
        peers="${peers}\"127.0.0.1:$NODE2_RPC\","
    fi
    if [ "$node_id" != "3" ]; then
        peers="${peers}\"127.0.0.1:$NODE3_RPC\","
    fi
    # Remove trailing comma
    peers="${peers%,}"

    cat > "$config_file" << EOF
# KalamDB Node $node_id Configuration
# Auto-generated by cluster-local.sh

[server]
host = "127.0.0.1"
port = $http_port
data_path = "$data_dir/data"
storage_path = "$data_dir/data/storage"

[logging]
level = "info"
format = "json"
file = "$data_dir/logs/server.jsonl"

[cluster]
enabled = true
cluster_id = "kalamdb-local-cluster"
node_id = $node_id
rpc_host = "127.0.0.1"
rpc_port = $rpc_port
peers = [$peers]
heartbeat_interval_ms = 150
election_timeout_min_ms = 300
election_timeout_max_ms = 500

[auth]
enabled = true
root_password = "kalamdb123"
jwt_secret = "local-cluster-jwt-secret-key-for-testing-only"
jwt_expiry_hours = 24
EOF

    echo "$config_file"
}

start_node() {
    local node_id=$1
    local http_port=$2
    local rpc_port=$3

    echo -e "${YELLOW}Starting node $node_id...${NC}"

    local config_file=$(create_node_config $node_id $http_port $rpc_port)
    local data_dir="$CLUSTER_DATA_DIR/node$node_id"
    local pid_file="$data_dir/server.pid"
    local log_file="$data_dir/logs/stdout.log"

    # Check if already running
    if [ -f "$pid_file" ]; then
        local old_pid=$(cat "$pid_file")
        if kill -0 "$old_pid" 2>/dev/null; then
            echo -e "${YELLOW}  Node $node_id already running (PID: $old_pid)${NC}"
            return 0
        fi
        rm -f "$pid_file"
    fi

    # Start the server
    local binary="$PROJECT_ROOT/target/release/kalamdb-server"
    if [ ! -f "$binary" ]; then
        binary="$PROJECT_ROOT/target/debug/kalamdb-server"
    fi

    if [ ! -f "$binary" ]; then
        echo -e "${RED}  Server binary not found. Run './scripts/cluster-local.sh build' first.${NC}"
        exit 1
    fi

    KALAMDB_CONFIG="$config_file" nohup "$binary" > "$log_file" 2>&1 &
    local pid=$!
    echo $pid > "$pid_file"

    # Wait for server to start
    sleep 2

    if kill -0 "$pid" 2>/dev/null; then
        echo -e "${GREEN}  ✓ Node $node_id started (PID: $pid, HTTP: $http_port, RPC: $rpc_port)${NC}"
    else
        echo -e "${RED}  ✗ Node $node_id failed to start. Check $log_file${NC}"
        return 1
    fi
}

stop_node() {
    local node_id=$1
    local data_dir="$CLUSTER_DATA_DIR/node$node_id"
    local pid_file="$data_dir/server.pid"

    if [ -f "$pid_file" ]; then
        local pid=$(cat "$pid_file")
        if kill -0 "$pid" 2>/dev/null; then
            echo -e "${YELLOW}Stopping node $node_id (PID: $pid)...${NC}"
            kill "$pid" 2>/dev/null || true
            sleep 1
            # Force kill if still running
            if kill -0 "$pid" 2>/dev/null; then
                kill -9 "$pid" 2>/dev/null || true
            fi
        fi
        rm -f "$pid_file"
        echo -e "${GREEN}  ✓ Node $node_id stopped${NC}"
    else
        echo -e "${YELLOW}  Node $node_id not running${NC}"
    fi
}

check_node_health() {
    local http_port=$1
    curl -sf "http://127.0.0.1:$http_port/v1/api/healthcheck" >/dev/null 2>&1
}

start_cluster() {
    print_header
    echo -e "${GREEN}Starting 3-node local cluster...${NC}"
    echo ""

    # Check if binary exists
    local binary="$PROJECT_ROOT/target/release/kalamdb-server"
    if [ ! -f "$binary" ]; then
        binary="$PROJECT_ROOT/target/debug/kalamdb-server"
    fi
    if [ ! -f "$binary" ]; then
        echo -e "${YELLOW}Server binary not found. Building...${NC}"
        build_server
    fi

    # Create data directory
    mkdir -p "$CLUSTER_DATA_DIR"

    # Start all nodes
    start_node $NODE1_ID $NODE1_HTTP $NODE1_RPC
    start_node $NODE2_ID $NODE2_HTTP $NODE2_RPC
    start_node $NODE3_ID $NODE3_HTTP $NODE3_RPC

    echo ""
    echo -e "${YELLOW}Waiting for cluster to initialize...${NC}"

    # Wait for all nodes to be healthy
    local healthy=0
    for i in {1..30}; do
        local count=0
        check_node_health $NODE1_HTTP && ((count++)) || true
        check_node_health $NODE2_HTTP && ((count++)) || true
        check_node_health $NODE3_HTTP && ((count++)) || true

        if [ "$count" -eq 3 ]; then
            healthy=1
            break
        fi
        sleep 1
    done

    echo ""
    if [ "$healthy" -eq 1 ]; then
        echo -e "${GREEN}╔═══════════════════════════════════════════════════════════════════╗${NC}"
        echo -e "${GREEN}║                    Cluster Ready!                                 ║${NC}"
        echo -e "${GREEN}╚═══════════════════════════════════════════════════════════════════╝${NC}"
        echo ""
        echo "Node 1: http://127.0.0.1:$NODE1_HTTP"
        echo "Node 2: http://127.0.0.1:$NODE2_HTTP"
        echo "Node 3: http://127.0.0.1:$NODE3_HTTP"
        echo ""
        echo "Root password: kalamdb123"
        echo ""
        echo "Connect with CLI:"
        echo "  kalam --server http://127.0.0.1:$NODE1_HTTP --username root --password kalamdb123"
        echo ""
        echo "Run cluster tests:"
        echo "  cd cli && cargo test --test cluster"
    else
        echo -e "${RED}Cluster failed to initialize. Check logs:${NC}"
        echo "  $CLUSTER_DATA_DIR/node1/logs/stdout.log"
        echo "  $CLUSTER_DATA_DIR/node2/logs/stdout.log"
        echo "  $CLUSTER_DATA_DIR/node3/logs/stdout.log"
        exit 1
    fi
}

stop_cluster() {
    print_header
    echo -e "${YELLOW}Stopping cluster...${NC}"
    echo ""

    stop_node 1
    stop_node 2
    stop_node 3

    echo ""
    echo -e "${GREEN}Cluster stopped.${NC}"
}

show_status() {
    print_header
    echo -e "${BLUE}Cluster Status:${NC}"
    echo ""

    for node_id in 1 2 3; do
        local data_dir="$CLUSTER_DATA_DIR/node$node_id"
        local pid_file="$data_dir/server.pid"
        local http_port=$((8080 + node_id))

        echo -n "  Node $node_id: "
        if [ -f "$pid_file" ]; then
            local pid=$(cat "$pid_file")
            if kill -0 "$pid" 2>/dev/null; then
                if check_node_health $http_port; then
                    echo -e "${GREEN}Running (PID: $pid, healthy)${NC}"
                else
                    echo -e "${YELLOW}Running (PID: $pid, not healthy yet)${NC}"
                fi
            else
                echo -e "${RED}Dead (stale PID file)${NC}"
            fi
        else
            echo -e "${RED}Not running${NC}"
        fi
    done

    echo ""
}

show_logs() {
    local node_id=$1
    local data_dir="$CLUSTER_DATA_DIR/node$node_id"
    local log_file="$data_dir/logs/stdout.log"

    if [ -f "$log_file" ]; then
        echo -e "${BLUE}=== Node $node_id Logs ===${NC}"
        tail -100 "$log_file"
    else
        echo -e "${RED}No log file found for node $node_id${NC}"
    fi
}

clean_cluster() {
    print_header
    echo -e "${YELLOW}Cleaning up cluster data...${NC}"

    stop_cluster

    if [ -d "$CLUSTER_DATA_DIR" ]; then
        rm -rf "$CLUSTER_DATA_DIR"
        echo -e "${GREEN}✓ Removed $CLUSTER_DATA_DIR${NC}"
    fi

    echo -e "${GREEN}Cleanup complete.${NC}"
}

# Main command handler
case "${1:-}" in
    start)
        start_cluster
        ;;
    stop)
        stop_cluster
        ;;
    restart)
        stop_cluster
        sleep 2
        start_cluster
        ;;
    status)
        show_status
        ;;
    logs)
        if [ -z "${2:-}" ]; then
            echo "Usage: $0 logs <node_number>"
            echo "  node_number: 1, 2, or 3"
            exit 1
        fi
        show_logs "$2"
        ;;
    clean)
        clean_cluster
        ;;
    build)
        build_server
        ;;
    *)
        echo "KalamDB Local Cluster Script"
        echo ""
        echo "Usage: $0 <command>"
        echo ""
        echo "Commands:"
        echo "  start     Start the 3-node cluster"
        echo "  stop      Stop all nodes"
        echo "  restart   Restart the cluster"
        echo "  status    Show cluster status"
        echo "  logs N    Show logs for node N (1, 2, or 3)"
        echo "  clean     Stop cluster and remove all data"
        echo "  build     Build the server binary"
        echo ""
        exit 1
        ;;
esac
