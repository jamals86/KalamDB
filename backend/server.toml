# KalamDB Server Configuration
# This is an example configuration file with all available settings.
# Copy this file to config.toml and adjust values for your environment.
#
# NOTE: Runtime configuration only!
# - Namespace and storage location configuration is stored in system tables (via kalamdb-sql)
# - This file contains only server runtime settings (ports, paths, limits, etc.)

[server]
# Server bind address (default: 127.0.0.1)
host = "0.0.0.0"

# Server port (default: 8080)
port = 8080

# Number of worker threads (0 = number of CPU cores)
# INCREASED FOR TEST LOAD: More workers handle concurrent test connections
# macOS has limited ephemeral ports (~16K), so more workers help process
# connections faster, reducing TIME_WAIT port exhaustion
workers = 24

# Enable HTTP/2 protocol support (default: true)
# When true, server uses automatic HTTP/1.1 and HTTP/2 cleartext (h2c) negotiation
# When false, server only supports HTTP/1.1
# HTTP/2 offers:
# - Multiplexed requests (multiple requests on single connection)
# - Header compression (HPACK)
# - Binary protocol (more efficient parsing)
# - Server push support (for future features)
enable_http2 = true

# API version (default: "v1")
# Controls the versioned endpoint prefix (e.g., /v1/api/sql)
api_version = "v1"

[storage]
# Base data directory for all KalamDB storage
# Subdirectories are automatically created:
#   ./data/rocksdb  - RocksDB hot storage (write buffer)
#   ./data/storage  - Parquet cold storage (flushed segments)
#   ./data/snapshots - Raft snapshots (consensus state)
data_path = "./data"

# Templates for table storage paths (used by 'local' storage)
# Available placeholders: {namespace}, {tableName}, {userId}
# Final paths: {data_path}/storage/{template}
# Examples:
#   Shared table: ./data/storage/myapp/products
#   User table: ./data/storage/myapp/preferences/user123
shared_tables_template = "{namespace}/{tableName}"
user_tables_template = "{namespace}/{tableName}/{userId}"

[storage.rocksdb]
# Write buffer size per column family in bytes (default: 2MB)
# Lower values reduce memory with many column families
# Formula: memory ~= write_buffer_size × max_write_buffers × num_column_families
# MEMORY OPTIMIZATION: Reduced for idle server (was 4MB)
write_buffer_size = 2097152

# Maximum number of write buffers (default: 2)
# Allows writes to continue while buffers are being flushed
max_write_buffers = 6

# Block cache size for reads in bytes (default: 4MB)
# Shared LRU cache across all column families
# MEMORY OPTIMIZATION: Reduced from 16MB to 4MB for idle server
block_cache_size = 4194304

# Maximum number of background compaction/flush jobs (default: 4)
max_background_jobs = 4

[datafusion]
# Memory limit for query execution in bytes (default: 256MB)
# Queries exceeding this limit will be terminated
memory_limit = 268435456

# Number of parallel threads for query execution (default: number of CPU cores)
# Set to 0 to auto-detect CPU count
query_parallelism = 0

# Maximum number of partitions per query (default: 8)
# Higher values increase parallelism but use more resources
max_partitions = 8

# Batch size for record processing (default: 2048 rows)
# Lower batch size reduces memory pressure
# MEMORY OPTIMIZATION: Reduced from 4096 to 2048 rows
batch_size = 2048

[flush]
# Default row limit for flush policies (default: 10000 rows)
# Tables without explicit flush policy will use this value
default_row_limit = 10000

# Default time interval for flush in seconds (default: 300s = 5 minutes)
# Tables will flush to Parquet after this duration
default_time_interval = 300

# Batch size for flush operations (default: 10000 rows)
# Controls how many rows are loaded into memory at once during flush
# Lower values reduce memory usage but may increase flush duration
# Set to 0 to load all rows at once (not recommended for large tables)
flush_batch_size = 10000

[retention]
# Default retention hours for soft-deleted rows (default: 168 hours = 7 days)
# Rows with _deleted=true will be kept in Parquet files for this duration
default_deleted_retention_hours = 168

[stream]
# Default TTL for stream table rows in seconds (default: 10 seconds)
# Stream tables are ephemeral - rows expire after this duration
default_ttl_seconds = 10

# Default maximum buffer size for stream tables (default: 10000 rows)
# Oldest rows are evicted when buffer exceeds this limit
default_max_buffer = 10000

# Stream eviction interval in seconds (default: 60 seconds = 1 minute)
# How often the background task checks and evicts expired events
eviction_interval_seconds = 60

[manifest_cache]
# Eviction job interval in seconds (default: 300s = 5 minutes)
# How often the eviction job runs to clean up stale manifest entries
eviction_interval_seconds = 300

# Maximum number of manifest entries in hot cache (default: 500)
# Older entries are evicted when this limit is reached (LRU policy)
max_entries = 500

# TTL in days for manifest eviction (default: 7 days)
# Manifests not accessed for this many days will be removed from both
# hot cache (RAM) and RocksDB persistent cache
# Set to 0 to disable manifest eviction (not recommended for long-running servers)
eviction_ttl_days = 7

# Weight factor for user table manifests (default: 10)
# User tables are evicted N times faster than shared tables.
user_table_weight_factor = 10

[limits]
# Maximum message size for REST API requests in bytes (default: 1MB)
max_message_size = 1048576

# Maximum rows that can be returned in a single query (default: 1000)
max_query_limit = 1000

# Default LIMIT for queries without explicit LIMIT clause (default: 50)
default_query_limit = 50

[logging]
# Log level: error, warn, info, debug, trace (default: info)
level = "info"

# Directory for all log files (default: "./logs")
# Server will create app.log, slow.log, and other log files in this directory
logs_path = "./logs"

# Also log to console/stdout (default: true)
log_to_console = true

# Log format: compact, pretty, json (default: compact)
format = "json"

# Slow query logging threshold in milliseconds (default: 1000ms = 1 second)
# Queries taking longer than this threshold will be logged to slow.log
# AND displayed as WARN in the console
# Set to a high value (e.g., 999999) to disable slow query logging
slow_query_threshold_ms = 1000

[logging.otlp]
# Export tracing spans to Jaeger OTLP receiver
enabled = true
# Jaeger gRPC OTLP endpoint
endpoint = "http://127.0.0.1:4317"
# Protocol: "grpc" or "http"
protocol = "grpc"
# Service name shown in Jaeger UI
service_name = "kalamdb-server"
# Export timeout in milliseconds
timeout_ms = 3000

[performance]
# Request timeout in seconds (default: 30s)
# Requests exceeding this duration will be terminated
request_timeout = 30

# Keep-alive timeout in seconds (default: 75s)
# HTTP keep-alive allows connection reuse, reducing TCP handshake overhead
# Tests benefit from longer keep-alive to reuse connections
keepalive_timeout = 75

# Maximum concurrent connections per worker (default: 25000)
# Includes both REST API and WebSocket connections
# INCREASED FOR TEST LOAD: Handles burst connections from concurrent tests
max_connections = 20000000

# TCP listen backlog - pending connections queue size (default: 2048)
# Controls how many connections can wait in the kernel queue before being accepted
# Increase for burst traffic or high-concurrency scenarios
# Recommended values:
#   - Development/Testing: 2048-4096 (handles burst test loads)
#   - Production: 4096-8192 (handles traffic spikes)
#   - High traffic: 8192+ (enterprise scale)
# Industry standards: Nginx (511), Apache (511), Caddy (1024), Actix (1024)
backlog = 4096

# Max blocking threads per worker for CPU-intensive operations (default: 512)
# Used for RocksDB I/O and synchronous operations
# INCREASED FOR TEST LOAD: More threads handle concurrent blocking operations
worker_max_blocking_threads = 4000

# Client request timeout in seconds (default: 5)
# Time allowed for client to send complete request headers
client_request_timeout = 10

# Client disconnect timeout in seconds (default: 2)
# Time allowed for graceful connection shutdown
client_disconnect_timeout = 5

# Maximum HTTP header size in bytes (default: 16384 = 16KB)
# Increase if you have large JWT tokens or custom headers  
max_header_size = 16384

[rate_limit]
# Maximum SQL queries per second per user (default: 100)
# Prevents query flooding from a single user
# NOTE: Set higher for development/testing environments
max_queries_per_sec = 100000

# Maximum WebSocket messages per second per connection (default: 50)
# Prevents message flooding on WebSocket connections
max_messages_per_sec = 10000

# Maximum concurrent live query subscriptions per user (default: 10)
# Limits total active subscriptions to prevent resource exhaustion
max_subscriptions_per_user = 200000

# Maximum authentication requests per IP per second (default: 20)
# Prevents brute force attacks and login flooding
# Applies to /auth/login, /auth/refresh, /setup endpoints
max_auth_requests_per_ip_per_sec = 200000

# Maximum concurrent connections per IP address (default: 100)
# Prevents a single IP from exhausting all server connections
max_connections_per_ip = 200000

# ⚠️ CRITICAL: Maximum requests per second per IP BEFORE authentication (default: 200)
# This is the main rate limit that triggers IP BANS
# Applied before auth to protect against unauthenticated floods
# If exceeded repeatedly (10+ times), IP will be banned for ban_duration_seconds
# For testing/development with high request rates, set to 100000+
max_requests_per_ip_per_sec = 200000

# Maximum request body size in bytes (default: 10MB)
# Prevents memory exhaustion from huge request payloads
request_body_limit_bytes = 104857600

# Duration in seconds to ban abusive IPs (default: 300 = 5 minutes)
# IPs that violate max_requests_per_ip_per_sec 10+ times are banned
ban_duration_seconds = 300

# Enable connection protection middleware (default: true)
# Set to false to completely disable rate limiting (NOT recommended for production)
enable_connection_protection = true

# Maximum cached entries for rate limiting state (default: 100,000)
cache_max_entries = 100000

# Time-to-idle for cached entries in seconds (default: 600 = 10 minutes)
cache_ttl_seconds = 600

# ============================================================================
# Security Settings
# ============================================================================
# CORS, WebSocket, and request limit configuration

[security]
# Maximum request body size in bytes (default: 10MB)
# Prevents memory exhaustion from large payloads
max_request_body_size = 10485760

# Maximum WebSocket message size in bytes (default: 1MB)
# Prevents memory exhaustion from large WebSocket messages
max_ws_message_size = 1048576

# Allowed WebSocket origins (if different from CORS origins)
# Leave empty to use CORS allowed_origins for WebSocket validation
allowed_ws_origins = []

# Strict WebSocket origin checking (default: false)
# If true, rejects WebSocket connections without Origin header
strict_ws_origin_check = false

# CORS Configuration (uses actix-cors)
# See: https://docs.rs/actix-cors
[security.cors]
# Allowed origins for CORS requests
# Use ["*"] or empty [] for any origin (development mode)
# For production, specify exact origins: ["https://app.example.com", "https://admin.example.com"]
allowed_origins = []

# Allowed HTTP methods (default: common REST methods)
allowed_methods = ["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"]

# Allowed HTTP headers
# Use ["*"] to allow any header
allowed_headers = ["Authorization", "Content-Type", "Accept", "Origin", "X-Requested-With"]

# Headers to expose to the browser (default: none)
# Example: ["X-Custom-Header", "X-Request-Id"]
expose_headers = []

# Allow credentials (cookies, authorization headers) (default: true)
# Note: If true, allowed_origins cannot be ["*"] in browsers
allow_credentials = true

# Preflight request cache max age in seconds (default: 3600 = 1 hour)
max_age = 3600

# Allow private network requests (default: false)
# Enables Access-Control-Request-Private-Network header support
allow_private_network = false

[websocket]
# Client heartbeat timeout in seconds (default: 10)
# How long to wait for client pong/activity before disconnecting.
# At high connection counts (>10K), increase to avoid false heartbeat timeouts
# caused by scheduling contention and TCP buffer pressure.
client_timeout_secs = 60

# Authentication timeout in seconds (default: 3)
# How long to wait for auth message after WebSocket connect
auth_timeout_secs = 10

# Heartbeat check interval in seconds (default: 5)
# How often the background heartbeat task iterates all connections.
# At high connection counts (>10K), increase to reduce CPU load and
# avoid thundering-herd ping storms.
heartbeat_interval_secs = 15

[authentication]
# Bcrypt cost factor for password hashing (default: 12, range: 4-31)
# Higher values = more secure but slower
# Changing this only affects NEW passwords
# Use 4 for development/benchmarking; 12+ for production
bcrypt_cost = 4

# Minimum password length (default: 8)
min_password_length = 8

# Maximum password length (default: 72, bcrypt limit)
# Note: Passwords longer than 72 bytes are truncated by bcrypt
max_password_length = 72

# Disable common password checking (default: false)
# If true, allows passwords like "password", "123456", etc.
# WARNING: Only disable for testing/development environments!
disable_common_password_check = false

# JWT configuration (for JWT Bearer token authentication)
# Secret key for JWT signature validation (minimum 32 characters recommended)
# IMPORTANT: Change this in production! Use a strong, random secret.
jwt_secret = "kalamdb-local-dev-2026-02-23-strong-jwt-secret-32plus"

# List of trusted JWT issuers (leave empty to accept any issuer)
# Add your OAuth provider domains here (e.g., "https://accounts.google.com", "https://github.com")
# Example for Google OAuth: ["https://accounts.google.com"]
# Example for GitHub OAuth: ["https://github.com"]
# Multiple issuers: ["https://accounts.google.com", "https://github.com", "https://kalamdb.io"]
jwt_trusted_issuers = "http://localhost:8081/realms/kalamdb"

# Auto-create local OAuth users from trusted provider subject/issuer when not found (default: false)
auto_create_users_from_provider = true

[shutdown]
# Timeout settings for graceful shutdown

[shutdown.flush]
# Timeout in seconds to wait for flush jobs to complete during graceful shutdown (default: 300)
timeout = 300

# Maximum number of concurrent jobs (default: 10)
# Controls how many jobs can execute simultaneously
max_concurrent = 10

# Maximum number of retry attempts per job (default: 3)
# Jobs will be retried this many times before being marked as permanently failed
max_retries = 3

# Initial retry backoff delay in milliseconds (default: 100ms)
# Delay increases exponentially with each retry (100ms, 200ms, 400ms, etc.)
retry_backoff_ms = 100

# Phase 11, T026: SQL Handler Execution Configuration
[execution]
# Handler execution timeout in seconds (default: 30)
# Maximum time allowed for a single SQL statement to execute
# Prevents hung requests from blocking resources
handler_timeout_seconds = 30

# Maximum number of parameters per statement (default: 50)
# Prevents memory exhaustion from excessive parameter arrays
max_parameters = 50

# Maximum size per parameter in bytes (default: 524288 = 512KB)
# Prevents memory exhaustion from individual large parameters
max_parameter_size_bytes = 524288

# ============================================================================
# CLUSTER CONFIGURATION (Raft-based Replication)
# ============================================================================
# ============================================================================
# Cluster Configuration (v0.2.0)
# ============================================================================
# Uncomment this section to enable cluster mode with Raft consensus.
# When enabled, all metadata and data operations go through Raft for consistency.
#
# Single-node cluster (for testing):
#   - Set node_id to 1
#   - Leave peers empty
#   - The cluster will auto-initialize as leader
#
# Multi-node cluster:
#   - Set unique node_id for each node (1, 2, 3, ...)
#   - List all OTHER nodes in peers
#   - Node with node_id=1 automatically bootstraps the cluster

[cluster]
# # Unique identifier for this cluster
# cluster_id = "prd-cluster"
# 
# # This node's unique ID (must be >= 1)
# # Node with node_id=1 is the designated bootstrap node
node_id = 1
# 
# # RPC address for Raft inter-node communication
# rpc_addr = "0.0.0.0:9100"
# 
# # API address for client HTTP requests (should match server.host:server.port)
# api_addr = "0.0.0.0:8080"
# #
# # Optional mTLS for inter-node gRPC (Raft + cluster RPC)
# # [cluster.rpc_tls]
# # enabled = true
# # ca_cert_path = "/etc/kalamdb/certs/cluster-ca.pem"
# # node_cert_path = "/etc/kalamdb/certs/node1.pem"
# # node_key_path = "/etc/kalamdb/certs/node1.key"
# 
# # Number of user data shards (default: 32)
# # MEMORY OPTIMIZATION: Reduced from 32 to 8 (saves ~5-8 MB)
# # Trade-off: Lower write parallelism (acceptable for development/testing)
user_shards = 8
# 
# # Number of shared data shards (default: 1)
# shared_shards = 1
# 
# # Raft heartbeat interval in milliseconds (default: 250)
# heartbeat_interval_ms = 250
# 
# # Raft election timeout range [min, max] in milliseconds (default: [500, 1000])
# election_timeout_ms = [500, 1000]
# 
# # Snapshot policy (default: "LogsSinceLast(1000)")
# # Applies to both single-node and multi-node clusters.
# # Options:
# #   - "LogsSinceLast(N)" - Create snapshot after N log entries since last snapshot
# #   - "Never" - Disable automatic snapshots (not recommended for production)
# # 
# # Lower values (e.g., 100) create snapshots more frequently:
# #   + Faster follower catchup (smaller log to replay)
# #   + Smaller memory footprint
# #   - More disk I/O for snapshot creation
# # 
# # Higher values (e.g., 10000) reduce snapshot frequency:
# #   + Less disk I/O
# #   - Slower follower catchup
# #   - Larger memory footprint
# snapshot_policy = "LogsSinceLast(1000)"
# 
# # Maximum number of snapshots to keep (default: 3)
# # Older snapshots are automatically deleted. Set to 0 to keep all snapshots.
# # For single-node deployments, you may want to set this to 1 to minimize disk usage.
# # 
# # Examples:
# #   max_snapshots_to_keep = 1   # Keep only the most recent snapshot (minimal disk usage)
# #   max_snapshots_to_keep = 3   # Keep last 3 snapshots (balanced approach)
# #   max_snapshots_to_keep = 0   # Keep all snapshots (useful for backup/recovery)
# max_snapshots_to_keep = 3
# 
# # Timeout in milliseconds to wait for learner catchup during cluster membership changes
# # (default: 5000ms = 5 seconds)
# replication_timeout_ms = 5000
# 
# # Minimum interval in milliseconds between reconnect attempts to an unreachable peer
# # (default: 3000ms = 3 seconds)
# reconnect_interval_ms = 3000
# 
# # NOTE: OpenRaft uses standard Raft quorum: (N/2)+1
# # For 3 nodes: quorum = 2 (majority required for commit)
# # For 5 nodes: quorum = 3
# # This is hardcoded in the Raft protocol and cannot be configured.
# # There is NO min_replication_nodes setting - Raft always uses quorum.
# 
# # Peer nodes (list all OTHER nodes in the cluster)
# # [[cluster.peers]]
# # node_id = 2
# # rpc_addr = "10.0.0.2:9100"
# # api_addr = "http://10.0.0.2:8080"
# # rpc_server_name = "node2.cluster.local"
# #
# # [[cluster.peers]]
# # node_id = 3
# # rpc_addr = "10.0.0.3:9100"
# # api_addr = "http://10.0.0.3:8080"
# # rpc_server_name = "node3.cluster.local"
