#!/bin/bash
# KalamDB Local Cluster Management Script (No Docker)
#
# This script runs a 3-node KalamDB cluster locally without Docker.
# Each node runs as a separate process with its own data directory.
#
# Usage:
#   ./scripts/cluster-local.sh start    - Start the 3-node cluster
#   ./scripts/cluster-local.sh stop     - Stop all nodes
#   ./scripts/cluster-local.sh restart  - Restart the cluster
#   ./scripts/cluster-local.sh status   - Check cluster status
#   ./scripts/cluster-local.sh logs N   - View logs from node N (1, 2, or 3)
#   ./scripts/cluster-local.sh clean    - Stop and remove all data
#   ./scripts/cluster-local.sh build    - Build the server binary
#   ./scripts/cluster-local.sh test     - Run cluster tests (cli/tests/cluster)
#   ./scripts/cluster-local.sh smoke    - Run smoke tests against leader
#   ./scripts/cluster-local.sh smoke-all - Run smoke tests against all nodes
#   ./scripts/cluster-local.sh verify   - Run consistency verification tests
#   ./scripts/cluster-local.sh full     - Run complete test suite (test + smoke-all + verify)
#
# Prerequisites:
#   - Rust toolchain installed (cargo, rustc)
#   - Port 8081, 8082, 8083 available (HTTP)
#   - Port 9081, 9082, 9083 available (Raft RPC)

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
CLUSTER_DATA_DIR="$PROJECT_ROOT/.cluster-local"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Node configuration
NODE1_HTTP=8081
NODE1_RPC=9081
NODE1_ID=1

NODE2_HTTP=8082
NODE2_RPC=9082
NODE2_ID=2

NODE3_HTTP=8083
NODE3_RPC=9083
NODE3_ID=3

ROOT_PASSWORD="kalamdb123"
CLUSTER_URLS="http://127.0.0.1:$NODE1_HTTP,http://127.0.0.1:$NODE2_HTTP,http://127.0.0.1:$NODE3_HTTP"

print_header() {
    echo ""
    echo -e "${BLUE}╔═══════════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${BLUE}║        KalamDB Local Cluster (No Docker)                          ║${NC}"
    echo -e "${BLUE}╚═══════════════════════════════════════════════════════════════════╝${NC}"
    echo ""
}

check_rust() {
    if ! command -v cargo &> /dev/null; then
        echo -e "${RED}Error: Cargo is not installed${NC}"
        echo "Please install Rust: https://rustup.rs/"
        exit 1
    fi
}

build_server() {
    print_header
    echo -e "${YELLOW}Building KalamDB server...${NC}"
    cd "$PROJECT_ROOT/backend"
    cargo build --release
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}✓ Server built successfully${NC}"
    else
        echo -e "${RED}✗ Build failed${NC}"
        exit 1
    fi
}

create_node_config() {
    local node_id=$1
    local http_port=$2
    local rpc_port=$3
    local data_dir="$CLUSTER_DATA_DIR/node$node_id"
    local config_file="$data_dir/server.toml"

    mkdir -p "$data_dir"
    mkdir -p "$data_dir/data"
    mkdir -p "$data_dir/logs"

    # Build peer list (all nodes except self)
    local peer_blocks=""
    if [ "$node_id" != "1" ]; then
        peer_blocks="${peer_blocks}
[[cluster.peers]]
node_id = 1
rpc_addr = \"127.0.0.1:$NODE1_RPC\"
api_addr = \"http://127.0.0.1:$NODE1_HTTP\"
"
    fi
    if [ "$node_id" != "2" ]; then
        peer_blocks="${peer_blocks}
[[cluster.peers]]
node_id = 2
rpc_addr = \"127.0.0.1:$NODE2_RPC\"
api_addr = \"http://127.0.0.1:$NODE2_HTTP\"
"
    fi
    if [ "$node_id" != "3" ]; then
        peer_blocks="${peer_blocks}
[[cluster.peers]]
node_id = 3
rpc_addr = \"127.0.0.1:$NODE3_RPC\"
api_addr = \"http://127.0.0.1:$NODE3_HTTP\"
"
    fi

    cat > "$config_file" << EOF
# KalamDB Node $node_id Configuration
# Auto-generated by cluster-local.sh

[server]
host = "127.0.0.1"
port = $http_port
workers = 0
api_version = "v1"
node_id = "node-$node_id"

[storage]
rocksdb_path = "$data_dir/data/rocksdb"
default_storage_path = "$data_dir/data/storage"
shared_tables_template = "{namespace}/{tableName}"
user_tables_template = "{namespace}/{tableName}/{userId}"

[limits]
max_message_size = 1048576
max_query_limit = 1000
default_query_limit = 50

[logging]
level = "info"
logs_path = "$data_dir/logs"
format = "json"

[performance]
request_timeout = 30
keepalive_timeout = 75
max_connections = 25000
backlog = 2048
worker_max_blocking_threads = 512
client_request_timeout = 5
client_disconnect_timeout = 2
max_header_size = 16384

[rate_limit]
max_queries_per_sec = 10000
max_messages_per_sec = 1000
max_subscriptions_per_user = 1000

[cluster]
enabled = true
cluster_id = "kalamdb-local-cluster"
node_id = $node_id
rpc_addr = "127.0.0.1:$rpc_port"
api_addr = "http://127.0.0.1:$http_port"
heartbeat_interval_ms = 150
election_timeout_ms = [300, 500]
replication_mode = "all"
replication_timeout_ms = 5000
min_replication_nodes = 3

$peer_blocks

[auth]
enabled = true
root_password = "$ROOT_PASSWORD"
jwt_secret = "local-cluster-jwt-secret-key-for-testing-only"
jwt_expiry_hours = 24
EOF

    echo "$config_file"
}

start_node() {
    local node_id=$1
    local http_port=$2
    local rpc_port=$3

    echo -e "${YELLOW}Starting node $node_id...${NC}"

    local config_file=$(create_node_config $node_id $http_port $rpc_port)
    local data_dir="$CLUSTER_DATA_DIR/node$node_id"
    local pid_file="$data_dir/server.pid"
    local log_file="$data_dir/logs/stdout.log"

    # Check if already running
    if [ -f "$pid_file" ]; then
        local old_pid=$(cat "$pid_file")
        if kill -0 "$old_pid" 2>/dev/null; then
            echo -e "${YELLOW}  Node $node_id already running (PID: $old_pid)${NC}"
            return 0
        fi
        rm -f "$pid_file"
    fi

    # Start the server
    local binary="$PROJECT_ROOT/target/release/kalamdb-server"
    if [ ! -f "$binary" ]; then
        binary="$PROJECT_ROOT/target/debug/kalamdb-server"
    fi

    if [ ! -f "$binary" ]; then
        echo -e "${RED}  Server binary not found. Run './scripts/cluster-local.sh build' first.${NC}"
        exit 1
    fi

    (cd "$data_dir" && nohup "$binary" > "$log_file" 2>&1) &
    local pid=$!
    echo $pid > "$pid_file"

    # Wait for server to start
    sleep 2

    if kill -0 "$pid" 2>/dev/null; then
        echo -e "${GREEN}  ✓ Node $node_id started (PID: $pid, HTTP: $http_port, RPC: $rpc_port)${NC}"
    else
        echo -e "${RED}  ✗ Node $node_id failed to start. Check $log_file${NC}"
        return 1
    fi
}

stop_node() {
    local node_id=$1
    local data_dir="$CLUSTER_DATA_DIR/node$node_id"
    local pid_file="$data_dir/server.pid"

    if [ -f "$pid_file" ]; then
        local pid=$(cat "$pid_file")
        if kill -0 "$pid" 2>/dev/null; then
            echo -e "${YELLOW}Stopping node $node_id (PID: $pid)...${NC}"
            kill "$pid" 2>/dev/null || true
            sleep 1
            # Force kill if still running
            if kill -0 "$pid" 2>/dev/null; then
                kill -9 "$pid" 2>/dev/null || true
            fi
        fi
        rm -f "$pid_file"
        echo -e "${GREEN}  ✓ Node $node_id stopped${NC}"
    else
        echo -e "${YELLOW}  Node $node_id not running${NC}"
    fi
}

check_node_health() {
    local http_port=$1
    curl -sf "http://127.0.0.1:$http_port/v1/api/healthcheck" >/dev/null 2>&1
}

start_cluster() {
    print_header
    echo -e "${GREEN}Starting 3-node local cluster...${NC}"
    echo ""

    # Check if binary exists
    local binary="$PROJECT_ROOT/target/release/kalamdb-server"
    if [ ! -f "$binary" ]; then
        binary="$PROJECT_ROOT/target/debug/kalamdb-server"
    fi
    if [ ! -f "$binary" ]; then
        echo -e "${YELLOW}Server binary not found. Building...${NC}"
        build_server
    fi

    # Create data directory
    mkdir -p "$CLUSTER_DATA_DIR"

    # Start all nodes
    start_node $NODE1_ID $NODE1_HTTP $NODE1_RPC
    start_node $NODE2_ID $NODE2_HTTP $NODE2_RPC
    start_node $NODE3_ID $NODE3_HTTP $NODE3_RPC

    echo ""
    echo -e "${YELLOW}Waiting for cluster to initialize...${NC}"

    # Wait for all nodes to be healthy
    local healthy=0
    for i in {1..30}; do
        local count=0
        check_node_health $NODE1_HTTP && ((count++)) || true
        check_node_health $NODE2_HTTP && ((count++)) || true
        check_node_health $NODE3_HTTP && ((count++)) || true

        if [ "$count" -eq 3 ]; then
            healthy=1
            break
        fi
        sleep 1
    done

    echo ""
    if [ "$healthy" -eq 1 ]; then
        echo -e "${GREEN}╔═══════════════════════════════════════════════════════════════════╗${NC}"
        echo -e "${GREEN}║                    Cluster Ready!                                 ║${NC}"
        echo -e "${GREEN}╚═══════════════════════════════════════════════════════════════════╝${NC}"
        echo ""
        echo "Node 1: http://127.0.0.1:$NODE1_HTTP"
        echo "Node 2: http://127.0.0.1:$NODE2_HTTP"
        echo "Node 3: http://127.0.0.1:$NODE3_HTTP"
        echo ""
        echo "Root password: $ROOT_PASSWORD"
        echo ""
        echo "Connect with CLI:"
        echo "  kalam --server http://127.0.0.1:$NODE1_HTTP --username root --password kalamdb123"
        echo ""
        echo "Run cluster tests:"
        echo "  cd cli && cargo test --test cluster"
    else
        echo -e "${RED}Cluster failed to initialize. Check logs:${NC}"
        echo "  $CLUSTER_DATA_DIR/node1/logs/stdout.log"
        echo "  $CLUSTER_DATA_DIR/node2/logs/stdout.log"
        echo "  $CLUSTER_DATA_DIR/node3/logs/stdout.log"
        exit 1
    fi
}

stop_cluster() {
    print_header
    echo -e "${YELLOW}Stopping cluster...${NC}"
    echo ""

    stop_node 1
    stop_node 2
    stop_node 3

    echo ""
    echo -e "${GREEN}Cluster stopped.${NC}"
}

show_status() {
    print_header
    echo -e "${BLUE}Cluster Status:${NC}"
    echo ""

    for node_id in 1 2 3; do
        local data_dir="$CLUSTER_DATA_DIR/node$node_id"
        local pid_file="$data_dir/server.pid"
        local http_port=$((8080 + node_id))

        echo -n "  Node $node_id: "
        if [ -f "$pid_file" ]; then
            local pid=$(cat "$pid_file")
            if kill -0 "$pid" 2>/dev/null; then
                if check_node_health $http_port; then
                    echo -e "${GREEN}Running (PID: $pid, healthy)${NC}"
                else
                    echo -e "${YELLOW}Running (PID: $pid, not healthy yet)${NC}"
                fi
            else
                echo -e "${RED}Dead (stale PID file)${NC}"
            fi
        else
            echo -e "${RED}Not running${NC}"
        fi
    done

    echo ""
}

show_logs() {
    local node_id=$1
    local data_dir="$CLUSTER_DATA_DIR/node$node_id"
    local log_file="$data_dir/logs/stdout.log"

    if [ -f "$log_file" ]; then
        echo -e "${BLUE}=== Node $node_id Logs ===${NC}"
        tail -100 "$log_file"
    else
        echo -e "${RED}No log file found for node $node_id${NC}"
    fi
}

clean_cluster() {
    print_header
    echo -e "${YELLOW}Cleaning up cluster data...${NC}"

    stop_cluster

    if [ -d "$CLUSTER_DATA_DIR" ]; then
        rm -rf "$CLUSTER_DATA_DIR"
        echo -e "${GREEN}✓ Removed $CLUSTER_DATA_DIR${NC}"
    fi

    echo -e "${GREEN}Cleanup complete.${NC}"
}

ensure_cluster_healthy() {
    local count=0
    check_node_health $NODE1_HTTP && ((count++)) || true
    check_node_health $NODE2_HTTP && ((count++)) || true
    check_node_health $NODE3_HTTP && ((count++)) || true

    if [ "$count" -lt 3 ]; then
        echo -e "${RED}Cluster is not healthy (healthy nodes: $count). Start the cluster first.${NC}"
        exit 1
    fi
}

run_cluster_tests() {
    print_header
    ensure_cluster_healthy
    echo -e "${YELLOW}Running cluster tests...${NC}"
    echo ""

    cd "$PROJECT_ROOT/cli"
    KALAMDB_CLUSTER_URLS="$CLUSTER_URLS" \
    KALAMDB_ROOT_PASSWORD="$ROOT_PASSWORD" \
    RUST_TEST_THREADS=1 \
        cargo test --test cluster -- --nocapture
}

run_smoke_tests() {
    print_header
    ensure_cluster_healthy
    echo -e "${YELLOW}Detecting cluster leader for smoke tests...${NC}"
    echo ""

    cd "$PROJECT_ROOT/cli"

    local leader_url
    leader_url=$(detect_leader_url || true)
    if [ -z "$leader_url" ]; then
        leader_url="http://127.0.0.1:$NODE1_HTTP"
        echo -e "${YELLOW}⚠️  Could not detect leader. Falling back to node 1: $leader_url${NC}"
    else
        echo -e "${GREEN}✓ Leader detected: $leader_url${NC}"
    fi

    KALAMDB_SERVER_URL="$leader_url" \
    KALAMDB_ROOT_PASSWORD="$ROOT_PASSWORD" \
    RUST_TEST_THREADS=1 \
        cargo test --test smoke -- --nocapture
}

run_smoke_tests_all_nodes() {
    print_header
    ensure_cluster_healthy
    echo -e "${YELLOW}Running smoke tests against ALL nodes...${NC}"
    echo ""

    cd "$PROJECT_ROOT/cli"

    local nodes=("http://127.0.0.1:$NODE1_HTTP" "http://127.0.0.1:$NODE2_HTTP" "http://127.0.0.1:$NODE3_HTTP")
    local passed=0
    local failed=0

    for node_url in "${nodes[@]}"; do
        echo ""
        echo -e "${BLUE}════════════════════════════════════════════════════════════════${NC}"
        echo -e "${BLUE}Testing node: $node_url${NC}"
        echo -e "${BLUE}════════════════════════════════════════════════════════════════${NC}"
        echo ""

        if KALAMDB_SERVER_URL="$node_url" \
           KALAMDB_ROOT_PASSWORD="$ROOT_PASSWORD" \
           RUST_TEST_THREADS=1 \
           cargo test --test smoke smoke_test_core_operations -- --nocapture; then
            echo -e "${GREEN}✓ Core operations passed on $node_url${NC}"
            ((passed++))
        else
            echo -e "${RED}✗ Core operations failed on $node_url${NC}"
            ((failed++))
        fi
    done

    echo ""
    echo -e "${GREEN}╔═══════════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${GREEN}║                    Smoke Tests Complete                           ║${NC}"
    echo -e "${GREEN}╚═══════════════════════════════════════════════════════════════════╝${NC}"
    echo ""
    echo "Passed: $passed / ${#nodes[@]}"
    echo "Failed: $failed / ${#nodes[@]}"

    if [ "$failed" -gt 0 ]; then
        exit 1
    fi
}

run_verification_tests() {
    print_header
    ensure_cluster_healthy
    echo -e "${YELLOW}Running consistency verification tests...${NC}"
    echo ""

    cd "$PROJECT_ROOT/cli"

    echo -e "${BLUE}Running system tables replication tests...${NC}"
    KALAMDB_CLUSTER_URLS="$CLUSTER_URLS" \
    KALAMDB_ROOT_PASSWORD="$ROOT_PASSWORD" \
    RUST_TEST_THREADS=1 \
        cargo test --test cluster cluster_test_system_tables -- --nocapture

    echo ""
    echo -e "${BLUE}Running subscription tests...${NC}"
    KALAMDB_CLUSTER_URLS="$CLUSTER_URLS" \
    KALAMDB_ROOT_PASSWORD="$ROOT_PASSWORD" \
    RUST_TEST_THREADS=1 \
        cargo test --test cluster cluster_test_subscription -- --nocapture

    echo ""
    echo -e "${BLUE}Running table identity tests...${NC}"
    KALAMDB_CLUSTER_URLS="$CLUSTER_URLS" \
    KALAMDB_ROOT_PASSWORD="$ROOT_PASSWORD" \
    RUST_TEST_THREADS=1 \
        cargo test --test cluster cluster_test_table_identity -- --nocapture

    echo ""
    echo -e "${BLUE}Running final consistency tests...${NC}"
    KALAMDB_CLUSTER_URLS="$CLUSTER_URLS" \
    KALAMDB_ROOT_PASSWORD="$ROOT_PASSWORD" \
    RUST_TEST_THREADS=1 \
        cargo test --test cluster cluster_test_final -- --nocapture

    echo ""
    echo -e "${GREEN}╔═══════════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${GREEN}║               Verification Tests Complete                         ║${NC}"
    echo -e "${GREEN}╚═══════════════════════════════════════════════════════════════════╝${NC}"
}

run_full_test_suite() {
    print_header
    ensure_cluster_healthy
    echo -e "${YELLOW}Running FULL cluster test suite...${NC}"
    echo ""
    echo "This includes:"
    echo "  1. All cluster replication tests"
    echo "  2. Smoke tests on all nodes"
    echo "  3. Consistency verification"
    echo ""

    local start_time=$(date +%s)

    # Run cluster tests
    echo -e "${BLUE}═══════════════════════════════════════════════════════════════════${NC}"
    echo -e "${BLUE}PHASE 1: Cluster Tests${NC}"
    echo -e "${BLUE}═══════════════════════════════════════════════════════════════════${NC}"
    run_cluster_tests

    # Run smoke tests on all nodes
    echo -e "${BLUE}═══════════════════════════════════════════════════════════════════${NC}"
    echo -e "${BLUE}PHASE 2: Multi-Node Smoke Tests${NC}"
    echo -e "${BLUE}═══════════════════════════════════════════════════════════════════${NC}"
    run_smoke_tests_all_nodes

    # Run verification tests
    echo -e "${BLUE}═══════════════════════════════════════════════════════════════════${NC}"
    echo -e "${BLUE}PHASE 3: Consistency Verification${NC}"
    echo -e "${BLUE}═══════════════════════════════════════════════════════════════════${NC}"
    run_verification_tests

    local end_time=$(date +%s)
    local duration=$((end_time - start_time))

    echo ""
    echo -e "${GREEN}╔═══════════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${GREEN}║                 FULL TEST SUITE COMPLETE                          ║${NC}"
    echo -e "${GREEN}╠═══════════════════════════════════════════════════════════════════╣${NC}"
    echo -e "${GREEN}║  Duration: ${duration}s                                                     ${NC}"
    echo -e "${GREEN}║  All tests passed!                                                ║${NC}"
    echo -e "${GREEN}╚═══════════════════════════════════════════════════════════════════╝${NC}"
}

detect_leader_url() {
    local query="SELECT api_addr, is_leader FROM system.cluster"
    local response

    response=$(
        curl -s \
            -u "root:$ROOT_PASSWORD" \
            -H "Content-Type: application/json" \
            -d "{\"sql\":\"$query\"}" \
            "http://127.0.0.1:$NODE1_HTTP/v1/api/sql"
    )

    if [ -z "$response" ]; then
        return 1
    fi

    python3 - "$response" << 'PY'
import json
import sys

if len(sys.argv) < 2:
    sys.exit(1)

try:
    data = json.loads(sys.argv[1])
except json.JSONDecodeError:
    sys.exit(1)

results = data.get("results") or []
if not results:
    sys.exit(1)

rows = results[0].get("rows") or []
for row in rows:
    if len(row) >= 2 and row[1] is True:
        api_addr = row[0]
        if api_addr:
            print(api_addr)
            sys.exit(0)

sys.exit(1)
PY
}

# Main command handler
case "${1:-}" in
    start)
        start_cluster
        ;;
    stop)
        stop_cluster
        ;;
    restart)
        stop_cluster
        sleep 2
        start_cluster
        ;;
    status)
        show_status
        ;;
    logs)
        if [ -z "${2:-}" ]; then
            echo "Usage: $0 logs <node_number>"
            echo "  node_number: 1, 2, or 3"
            exit 1
        fi
        show_logs "$2"
        ;;
    clean)
        clean_cluster
        ;;
    build)
        build_server
        ;;
    test)
        run_cluster_tests
        ;;
    smoke)
        run_smoke_tests
        ;;
    smoke-all)
        run_smoke_tests_all_nodes
        ;;
    verify)
        run_verification_tests
        ;;
    full)
        run_full_test_suite
        ;;
    *)
        echo "KalamDB Local Cluster Script"
        echo ""
        echo "Usage: $0 <command>"
        echo ""
        echo "Commands:"
        echo "  start      Start the 3-node cluster"
        echo "  stop       Stop all nodes"
        echo "  restart    Restart the cluster"
        echo "  status     Show cluster status"
        echo "  logs N     Show logs for node N (1, 2, or 3)"
        echo "  clean      Stop cluster and remove all data"
        echo "  build      Build the server binary"
        echo "  test       Run cluster tests (cli/tests/cluster)"
        echo "  smoke      Run smoke tests against leader"
        echo "  smoke-all  Run smoke tests against all nodes"
        echo "  verify     Run consistency verification tests"
        echo "  full       Run complete test suite (test + smoke-all + verify)"
        echo ""
        exit 1
        ;;
esac
